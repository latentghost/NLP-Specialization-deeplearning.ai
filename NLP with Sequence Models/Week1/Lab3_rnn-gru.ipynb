{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from time import perf_counter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)                 # Random seed, so your results match ours\n",
    "emb = 128                       # Embedding size\n",
    "T = 256                         # Length of sequence\n",
    "h_dim = 16                      # Hidden State dimension\n",
    "h_0 = np.zeros((h_dim, 1))      # Initial Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w2 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w3 = random.standard_normal((h_dim, emb + h_dim))\n",
    "b1 = random.standard_normal((h_dim, 1))\n",
    "b2 = random.standard_normal((h_dim, 1))\n",
    "b3 = random.standard_normal((h_dim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization of input X\n",
    "X = random.standard_normal((T, emb, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lists of weights as you will need them for the two different layers\n",
    "weights_vanilla = [w1, b1]\n",
    "weights_GRU = [w1.copy(), w2, w3, b1.copy(), b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_V_RNN(inputs, weights): # Forward propagation for a vanilla RNN cell\n",
    "    x, h_t = inputs\n",
    "    wh, bh = weights\n",
    "\n",
    "    # Next Hidden State\n",
    "    h_t = np.dot(wh, np.concatenate([h_t, x])) + bh\n",
    "    h_t = sigmoid(h_t)\n",
    "    \n",
    "    # Transformation from h to y is considered with identity activation and weights\n",
    "    y = h_t\n",
    "    \n",
    "    return y, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_GRU(inputs, weights): # Forward propagation for a single GRU cell\n",
    "    x, h_t = inputs\n",
    "\n",
    "    # weights.\n",
    "    wu, wr, wc, bu, br, bc = weights\n",
    "\n",
    "    # Update gate\n",
    "    u = np.dot(wu, np.concatenate([h_t, x])) + bu\n",
    "    u = sigmoid(u)\n",
    "    \n",
    "    # Relevance gate\n",
    "    r = np.dot(wr, np.concatenate([h_t, x])) + br\n",
    "    r = sigmoid(r)\n",
    "    \n",
    "    # Candidate hidden state \n",
    "    c = np.dot(wc, np.concatenate([r * h_t, x])) + bc\n",
    "    c = np.tanh(c)\n",
    "    \n",
    "    # New Hidden state h_t\n",
    "    h_t = u * c + (1 - u) * h_t\n",
    "    \n",
    "    # Transformation from h to y is considered with identity activation and weights\n",
    "    y = h_t\n",
    "    \n",
    "    return y, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77779014e-01],\n",
       "       [-9.97986240e-01],\n",
       "       [-5.19958083e-01],\n",
       "       [-9.99999886e-01],\n",
       "       [-9.99707004e-01],\n",
       "       [-3.02197037e-04],\n",
       "       [-9.58733503e-01],\n",
       "       [ 2.10804828e-02],\n",
       "       [ 9.77365398e-05],\n",
       "       [ 9.99833090e-01],\n",
       "       [ 1.63200940e-08],\n",
       "       [ 8.51874303e-01],\n",
       "       [ 5.21399924e-02],\n",
       "       [ 2.15495959e-02],\n",
       "       [ 9.99878828e-01],\n",
       "       [ 9.77165472e-01]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_GRU([X[1], h_0], weights_GRU)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(fn, elems, weights, h_0):\n",
    "    h_t = h_0\n",
    "    ys = []\n",
    "    \n",
    "    for x in elems:\n",
    "        y, h_t = fn([x, h_t], weights)\n",
    "        ys.append(y)\n",
    "        \n",
    "    return ys, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2.06ms to run the forward method for the vanilla RNN.\n"
     ]
    }
   ],
   "source": [
    "# Simple RNN\n",
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_V_RNN, X, weights_vanilla, h_0)\n",
    "toc = perf_counter()\n",
    "RNN_time=(toc-tic)*1000\n",
    "print (f\"It took {RNN_time:.2f}ms to run the forward method for the vanilla RNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 4.23ms to run the forward method for the GRU.\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_GRU, X, weights_GRU, h_0)\n",
    "toc = perf_counter()\n",
    "GRU_time=(toc-tic)*1000\n",
    "print (f\"It took {GRU_time:.2f}ms to run the forward method for the GRU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(256, return_sequences=True, name='GRU_1_returns_seq'),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, name='GRU_2_returns_seq'),\n",
    "    # tf.keras.layers.GRU(64, name='GRU_3_returns_last_only'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " GRU_1_returns_seq (GRU)     (60, 50, 256)             228864    \n",
      "                                                                 \n",
      " GRU_2_returns_seq (GRU)     (60, 50, 128)             148224    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (60, 50, 10)              1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 378378 (1.44 MB)\n",
      "Trainable params: 378378 (1.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "sequence_length = 50\n",
    "word_vector_length = 40\n",
    "\n",
    "input_data = tf.random.normal([batch_size, sequence_length, word_vector_length])\n",
    "\n",
    "# Pass the data through the network\n",
    "prediction = model_GRU(input_data)\n",
    "\n",
    "# Show the summary of the model\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception encountered when calling layer 'sequential_1' (type Sequential).\n",
      "\n",
      "Input 0 of layer \"GRU_1_returns_seq\" is incompatible with the layer: expected shape=(None, None, 40), found shape=(60, 50, 44)\n",
      "\n",
      "Call arguments received by layer 'sequential_1' (type Sequential):\n",
      "  • inputs=tf.Tensor(shape=(60, 50, 44), dtype=float32)\n",
      "  • training=None\n",
      "  • mask=None\n"
     ]
    }
   ],
   "source": [
    "new_word_vector_length = 44  # Before it was 40\n",
    "# Keep the batch_size = 60 and sequence_length = 50 as originally\n",
    "input_data_1 = tf.random.normal([batch_size, sequence_length, new_word_vector_length])\n",
    "\n",
    "# Pass the data through the network. This should Fail (if you ran all the cells above)\n",
    "try:\n",
    "    prediction = model_GRU(input_data_1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " GRU_1_returns_seq (GRU)     (60, None, 256)           228864    \n",
      "                                                                 \n",
      " GRU_2_returns_seq (GRU)     (60, None, 128)           148224    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (60, None, 10)            1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 378378 (1.44 MB)\n",
      "Trainable params: 378378 (1.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_sequence_length = 55  # Before it was 50\n",
    "# Keep the batch_size = 60 and word_vector_length = 40 as originally\n",
    "input_data_2 = tf.random.normal([batch_size, new_sequence_length, word_vector_length])\n",
    "try:\n",
    "    prediction = model_GRU(input_data_2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "prediction.shape\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " GRU_1_returns_seq (GRU)     (None, None, 256)         228864    \n",
      "                                                                 \n",
      " GRU_2_returns_seq (GRU)     (None, None, 128)         148224    \n",
      "                                                                 \n",
      " GRU_3_returns_last_only (G  (None, 64)                37248     \n",
      " RU)                                                             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 414986 (1.58 MB)\n",
      "Trainable params: 414986 (1.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(256, return_sequences=True, name='GRU_1_returns_seq'),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, name='GRU_2_returns_seq'),\n",
    "    tf.keras.layers.GRU(64, name='GRU_3_returns_last_only'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_GRU_2.build([None, None, word_vector_length])\n",
    "\n",
    "model_GRU_2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
